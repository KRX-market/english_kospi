import streamlit as st

import pandas as pd

import requests

from bs4 import BeautifulSoup

import re

from datetime import datetime, timedelta

import time

import random



# 1. í˜ì´ì§€ ì„¤ì •

st.set_page_config(page_title="ì½”ìŠ¤í”¼ ì˜ë¬¸ê³µì‹œ í•„í„°ë§ ë„êµ¬", layout="wide")



st.title('ğŸ¯ ì˜¤ëŠ˜ì˜ ì½”ìŠ¤í”¼ ë²ˆì—­ëŒ€ìƒ ê³µì‹œ (ì „ì²´ í˜ì´ì§€ ì¡°íšŒ)')

st.markdown("---")



# 2. ë°ì´í„° ë¡œë“œ (CSV)

@st.cache_data

def load_reference_data():

    try:

        df_svc = pd.read_csv("kospi_format.csv", dtype=str)

        df_listed = pd.read_csv("kospi_company.csv", dtype=str)

        if not df_listed.empty and 'íšŒì‚¬ì½”ë“œ' in df_listed.columns:

            df_listed['íšŒì‚¬ì½”ë“œ'] = df_listed['íšŒì‚¬ì½”ë“œ'].astype(str).str.zfill(5)

        return df_svc, df_listed

    except Exception as e:

        st.error(f"âš ï¸ CSV íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        return pd.DataFrame(), pd.DataFrame()



df_svc, df_listed = load_reference_data()



# ìƒë‹¨ ê¸°ì¤€ ë°ì´í„° í‘œì‹œ

if not df_svc.empty and not df_listed.empty:

    col_ref1, col_ref2 = st.columns(2)

    with col_ref1:

        st.subheader("ğŸ“‹ ì§€ì›ëŒ€ìƒ ê³µì‹œì„œì‹")

        st.dataframe(df_svc, use_container_width=True, height=180)

    with col_ref2:

        st.subheader("ğŸ¢ ì§€ì›ëŒ€ìƒ íšŒì‚¬ëª©ë¡")

        st.dataframe(df_listed, use_container_width=True, height=180)



st.markdown("---")



# 3. ë‚ ì§œ ì„¤ì •

selected_date = st.date_input("ğŸ“… ì¡°íšŒì¼ì ì„ íƒ", value=datetime.today())

today_str = selected_date.strftime("%Y-%m-%d")



# 4. ë©€í‹° í˜ì´ì§€ í¬ë¡¤ë§ ì—”ì§„

def get_all_kind_data(date_str):

    main_url = "https://kind.krx.co.kr/disclosure/todaydisclosure.do"

    ajax_url = "https://kind.krx.co.kr/disclosure/todaydisclosure.do"

    

    headers = {

        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",

        "Referer": "https://kind.krx.co.kr/disclosure/todaydisclosure.do",

        "X-Requested-With": "XMLHttpRequest"

    }



    session = requests.Session()

    all_rows = []

    

    try:

        # Step 1: ì„¸ì…˜ ì´ˆê¸°í™”

        session.get(main_url, headers=headers)

        

        # Step 2: ë¨¼ì € 1í˜ì´ì§€ë¥¼ ê°€ì ¸ì™€ì„œ 'ì „ì²´ í˜ì´ì§€ ìˆ˜' í™•ì¸

        payload = {

            "method": "searchTodayDisclosureSub",

            "currentPageSize": 100,

            "pageIndex": 1,

            "orderMode": "0",

            "orderStat": "D",

            "forward": "todaydisclosure_sub",

            "marketType": "1",

            "selDate": date_str

        }

        

        first_resp = session.post(ajax_url, data=payload, headers=headers)

        soup = BeautifulSoup(first_resp.text, 'html.parser')

        

        # ì „ì²´ í˜ì´ì§€ ìˆ˜ ì¶”ì¶œ (ì˜ˆ: 1/3 í˜ì´ì§€ì—ì„œ '3' ì¶”ì¶œ)

        info_text = soup.select_one('.info.type-00')

        total_pages = 1

        if info_text:

            page_match = re.search(r'/(\d+) í˜ì´ì§€', info_text.text)

            if page_match:

                total_pages = int(page_match.group(1))

        

        # Step 3: ê° í˜ì´ì§€ ìˆœíšŒí•˜ë©° ë°ì´í„° ìˆ˜ì§‘

        progress_bar = st.progress(0)

        for page in range(1, total_pages + 1):

            payload["pageIndex"] = page

            resp = session.post(ajax_url, data=payload, headers=headers)

            p_soup = BeautifulSoup(resp.text, 'html.parser')

            

            table = p_soup.find('table', class_='list type-00 mt10')

            if not table: continue

            

            for tr in table.find('tbody').find_all('tr'):

                tds = tr.find_all('td')

                if len(tds) < 5 or "ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤" in tr.text: continue

                

                comp_a = tds[1].find('a')

                comp_code = ""

                if comp_a and comp_a.has_attr('onclick'):

                    code_match = re.search(r"companysummary_open\('(\d+)'\)", comp_a['onclick'])

                    if code_match: comp_code = code_match.group(1)

                

                title_a = tds[2].find('a')

                title = title_a.get('title', '').strip() if title_a else ""

                acpt_no = ""

                if title_a and title_a.has_attr('onclick'):

                    no_match = re.search(r"openDisclsViewer\('(\d+)'", title_a['onclick'])

                    if no_match: acpt_no = no_match.group(1)

                

                all_rows.append({

                    'ì‹œê°„': tds[0].text.strip(),

                    'íšŒì‚¬ì½”ë“œ': comp_code,

                    'íšŒì‚¬ëª…': tds[1].text.strip(),

                    'ê³µì‹œì œëª©': title,

                    'ì œì¶œì¸': tds[3].text.strip(),

                    'ìƒì„¸URL': f"https://kind.krx.co.kr/common/disclsviewer.do?method=search&acptno={acpt_no}" if acpt_no else ""

                })

            

            # ì§„í–‰ë°” ì—…ë°ì´íŠ¸ ë° ë§¤ë„ˆ ëŒ€ê¸°

            progress_bar.progress(page / total_pages)

            time.sleep(random.uniform(0.2, 0.5))

            

        return pd.DataFrame(all_rows)



    except Exception as e:

        st.error(f"âŒ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")

        return pd.DataFrame()



# 5. ì‹¤í–‰ ë° í•„í„°ë§

if st.button('ğŸš€ ëˆ„ë½ ì—†ëŠ” ì „ìˆ˜ ì¡°ì‚¬ ì‹œì‘'):

    with st.spinner('ì˜¤ëŠ˜ì˜ ëª¨ë“  ê³µì‹œ í˜ì´ì§€ë¥¼ í™•ì¸í•˜ê³  ìˆìŠµë‹ˆë‹¤...'):

        df_raw = get_all_kind_data(today_str)

        

        if not df_raw.empty:

            target_forms = df_svc['ì„œì‹ëª…'].unique().tolist()

            target_codes = df_listed['íšŒì‚¬ì½”ë“œ'].tolist()



            def filter_logic(row):

                title = row['ê³µì‹œì œëª©']

                code = row['íšŒì‚¬ì½”ë“œ']

                if title.startswith(("ì¶”ê°€ìƒì¥", "ë³€ê²½ìƒì¥")): return False

                return any(f in title for f in target_forms) and (code in target_codes)



            final_df = df_raw[df_raw.apply(filter_logic, axis=1)]



            st.subheader(f"ğŸ“Š ì˜¤ëŠ˜ ì „ì²´ ê³µì‹œ {len(df_raw)}ê±´ ì¤‘ í•„í„°ë§ ê²°ê³¼ ({len(final_df)}ê±´)")

            if not final_df.empty:

                st.dataframe(

                    final_df[['ì‹œê°„', 'íšŒì‚¬ëª…', 'ê³µì‹œì œëª©', 'ì œì¶œì¸', 'ìƒì„¸URL']],

                    column_config={"ìƒì„¸URL": st.column_config.LinkColumn("ê³µì‹œë³´ê¸°")},

                    hide_index=True, use_container_width=True

                )

            else:

                st.info("ì¡°ê±´ì— ë§ëŠ” ê³µì‹œê°€ 1ê±´ë„ ì—†ìŠµë‹ˆë‹¤.")

        else:

            st.warning("ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (íœ´ì¼ì´ê±°ë‚˜ ì ‘ê·¼ ì°¨ë‹¨)")


